<?xml version="1.0" encoding="utf-8"?>
<search>
  <entry>
    <title>9.25-学习计算机网络MAC层、操作系统X86架构</title>
    <url>/posts/3/</url>
    <content><![CDATA[<ol>
<li>x86架构<ol>
<li>需求<ol>
<li>做生意要开放的营商环境，所以操作系统也需要一个统一的开放的架构</li>
</ol>
</li>
<li>计算机的工作模式是什么样的？</li>
<li>cpu和内存是如何配合工作的？<ol>
<li>cpu包裹三个部分，运算、数据、控制单元</li>
<li>从之后面就讲到了内存的数据和总线的位数有无统一标准？没有标准操作系统很难办，因为操作系统作为软件层没办法实现通用的运算逻辑</li>
</ol>
</li>
<li>由此出现了X86架构<ol>
<li>基本概念<ol>
<li>英特尔的技术是行业的开放事实标准。由于这个系列开端于 8086，因此称为 x86 架构。</li>
</ol>
</li>
<li>8086处理器<ol>
<li>数据单元<ol>
<li>内部有8个16位的通用寄存器，分别是AX BX CX DX SP BP SI DI 用于暂存数据</li>
<li>AX BX CX DX 可以分成两个8位的寄存器使用，分别是AH AL BH BL etc，这样长短数据都可以暂存了</li>
</ol>
</li>
<li>控制单元<ol>
<li>IP寄存器就是指令指针寄存器，指向代码段中下一条指令的位置。cpu会根据它来不断地将指令从内存的代码段中加载到cpu的指令队列中，然后交给运算单元执行。</li>
</ol>
</li>
</ol>
</li>
</ol>
</li>
</ol>
</li>
<li>计算机网络<ol>
<li>MAC层<ol>
<li>基本概念<ol>
<li>MAC层即媒体访问控制，数据链路层。</li>
</ol>
</li>
<li>解决的主要问题<ol>
<li>这个包是发给谁的？谁该接收？</li>
<li>如果大家都在发，谁先发，谁后发？会不会混乱？</li>
<li>如果发送的时候出现错误怎么办？</li>
<li>一个广播的网络里面接入了N台机器，怎么直到每个MAC地址是谁？</li>
<li>能否直到目标MAC地址就将数据包转到对应口的机器，从而不广播呢？</li>
</ol>
</li>
<li>解决方案<ol>
<li>针对问题一，通过MAC地址来确定发给谁，谁接收。有了目标MAC地址和源MAC地址，数据包在链路上广播，MAC的网卡才能发现这个包是给他的。MAC的网卡把包收进来，然后打开IP包交给网络层。</li>
<li>针对第二个问题，学名叫多路访问，有很多算法可以解决多路访问问题<ol>
<li>信道划分，即分多个车道，每个车道中的车你走你的，我走我的</li>
<li>轮流协议，就像车今天单号出行，明天双号出行，轮着来</li>
<li>随机接入协议，有事儿先出门，发现特堵，就回去，错峰再出行（以太网）</li>
</ol>
</li>
<li>针对问题三，对于以太网，MAC网络包中的最后4Byte是CRC循环冗余检测，通过XOR异或算法来计算整个包是否在发送过程中出现错误。</li>
<li>针对第四个问题，MAC层使用了ARP协议，也就是已知IP地址，求MAC地址的协议。具体机制是发送方“吼”一声，发送一个广播包，谁是这个IP谁来回答，为了避免每次都用ARP请求，机器会进行ARP缓存，并且过一段时间过期更新。<ol>
<li>ARP报文</li>
</ol>
</li>
<li>针对第五个问题，有一个MAC层设备称为交换机，交换机会记住第一次广播吼的MAC地址，形成一个转发表，这样以后的目的地址是该MAC地址的就直接发送到这个口即可，不必广播了。</li>
</ol>
</li>
<li>MAC网络包格式<ol>
<li>前6byte是目标MAC地址，再是6byte的源MAC地址，然后是2byte的类型（0800表示IP数据报，0806表示ARP请求和应答），然后是46－1500byte的数据，最后是4byteCRC循环冗余校验码</li>
</ol>
</li>
</ol>
</li>
</ol>
</li>
</ol>
]]></content>
      <categories>
        <category>Diary</category>
      </categories>
      <tags>
        <tag>Diary</tag>
      </tags>
  </entry>
  <entry>
    <title>数据库-串联一致性读、当前读、行锁：事务是隔离的还是不隔离的【事务、锁】</title>
    <url>/posts/9/</url>
    <content><![CDATA[<h1 id="视图的两个概念"><a href="#视图的两个概念" class="headerlink" title="视图的两个概念"></a>视图的两个概念</h1><ul>
<li>一个是view，它是一个用查询语句定义的虚拟表，在调用的时候执行查询语句并生成结果。创建视图的语法是create view …，而它的查询方法与表一样。</li>
<li>另一个是InnoDB在实现MVCC（多版本并发控制）时用到的一致性读视图，即consistent read view，用于支持RC（Read Committed，读提交）和RR（Repeatable Read，可重复读）隔离级别的实现。</li>
</ul>
<h1 id="“快照”在MVCC里是怎么工作的？"><a href="#“快照”在MVCC里是怎么工作的？" class="headerlink" title="“快照”在MVCC里是怎么工作的？"></a>“快照”在MVCC里是怎么工作的？</h1><ul>
<li>在可重复读隔离级别下，事务在启动的时候就“拍了个快照”。这个快照是基于整库的。</li>
<li>每个事务都有一个ID，当事务对每行数据做出更新的时候将会生成一个row trx_id，值和事务ID一样，并且会生成undo log（回滚日志），通过回滚日志和当前版本可以回退到其他版本。</li>
<li>可见和不可见问题<ul>
<li>对于自己的更新总是可见的</li>
<li>版本未提交，不可见；</li>
<li>版本已提交，但是是在视图创建后提交的，不可见；</li>
<li>版本已提交，而且是在视图创建前提交的，可见；</li>
</ul>
</li>
</ul>
<h1 id="更新逻辑"><a href="#更新逻辑" class="headerlink" title="更新逻辑"></a>更新逻辑</h1><ul>
<li>当事务要去更新数据的时候，就不能再在历史版本上更新了。更新数据都是先读后写的，而这个读，只能读当前版本的值，称为“当前读”（current read）。</li>
<li>假如select语句加锁，也是“当前读”。下面这两个 select 语句，就是分别加了读锁（S 锁，共享锁）和写锁（X 锁，排他锁）。<ul>
<li>select k from t where id&#x3D;1 lock in share mode;</li>
<li>select k from t where id&#x3D;1 for update;</li>
</ul>
</li>
</ul>
<h1 id="事务的可重复读能力是怎么实现的？"><a href="#事务的可重复读能力是怎么实现的？" class="headerlink" title="事务的可重复读能力是怎么实现的？"></a>事务的可重复读能力是怎么实现的？</h1><ul>
<li>可重复读的核心是一致性读；而事务更新数据的时候，只能用当前读；如果当前的记录的行锁被其他事务占用了的话，就需要进入锁等待。</li>
</ul>
]]></content>
      <categories>
        <category>MySQL</category>
      </categories>
      <tags>
        <tag>事务</tag>
        <tag>锁</tag>
        <tag>MySQL</tag>
      </tags>
  </entry>
  <entry>
    <title>Go并发编程</title>
    <url>/posts/2/</url>
    <content><![CDATA[<p><img src= "/img/loading.gif" data-src="https://cdn.jsdelivr.net/gh/lovevivi121/PicGo/img/Go%E5%B9%B6%E5%8F%91%E7%BC%96%E7%A8%8B%E6%9E%81%E5%AE%A2%E6%97%B6%E9%97%B4.png"></p>
]]></content>
      <categories>
        <category>GO</category>
      </categories>
      <tags>
        <tag>总结</tag>
        <tag>blog</tag>
      </tags>
  </entry>
  <entry>
    <title>操作系统-molloc和零拷贝相关</title>
    <url>/posts/1/</url>
    <content><![CDATA[<h1 id="开发流程："><a href="#开发流程：" class="headerlink" title="开发流程："></a>开发流程：</h1><ol>
<li>修改公告 在source&#x2F;_data&#x2F;butterfly.yml中找到并修改</li>
<li>添加文章 在source&#x2F;_posts 下面的对应分类中copy本模板然后修改内容即可</li>
<li>添加分类 在写文章的时候写上对应分类即可</li>
<li>添加图片 首先添加到图床中，然后将链接放上去</li>
<li>上传 运行命令 <code>hexo s</code>（本地预览），<code>hexo clean</code>（清除生成文件），<code>hexo g</code>（生成网页）,<code>hexo deploy</code>（部署）</li>
</ol>
]]></content>
      <categories>
        <category>blog</category>
      </categories>
      <tags>
        <tag>总结</tag>
        <tag>blog</tag>
      </tags>
  </entry>
  <entry>
    <title>开发模板</title>
    <url>/posts/12/</url>
    <content><![CDATA[<h1 id="molloc"><a href="#molloc" class="headerlink" title="molloc"></a>molloc</h1><ul>
<li>molloc有两种实现方式，brk和mmap。当申请内存小于128kb时使用brk，大于则使用mmap。brk申请的空间在free释放时不会真的释放，而是会放回内存池；它的好处是可以一次分配更大内存，避免频繁申请内存带来的切换开销；但是会产生内存碎片</li>
<li>mmap申请的内存空间在free时会归还给系统。但是每次mmap申请的内存第一次访问都需要触发缺页中断；并且需要进入内核，要频繁的状态切换。mmap的原理时直接将虚拟地址与内核缓冲区地址进行映射，避免内核缓冲区到用户缓冲区的copy</li>
</ul>
<h1 id="零拷贝"><a href="#零拷贝" class="headerlink" title="零拷贝"></a>零拷贝</h1><ul>
<li>零拷贝是说不需要CPU将数据拷贝到另一个区域。</li>
<li>首先是DMA代替CPU将数据从磁盘缓冲区调入内核缓冲区。</li>
<li>由于数据加工都是在内核空间完成的，因此也不需要将数据从内核缓冲区拷贝到用户缓冲区。这一步有两种方法<ul>
<li>第一种是使用mmap+write。用mmap代替read，避免copy，此时仍然需要4次状态切换以及一次缓冲区到socket的拷贝</li>
<li>第二种是使用sendfile。用sendfile代替read和write，这样只需要两次状态切换。同时缓冲区直接通过SGDMA传到网卡，实现真正的零拷贝</li>
</ul>
</li>
</ul>
<h1 id="如何实现大文件传输"><a href="#如何实现大文件传输" class="headerlink" title="如何实现大文件传输"></a>如何实现大文件传输</h1><ul>
<li>针对大文件传输，不能使用零拷贝，因为pagecache不会起作用，导致其他小文件无法享用pagecache，在高并发场景下会造成严重性能问题。因此采用异步IO，绕过pagecache，同时避免read的阻塞问题。<br><img src= "/img/loading.gif" data-src="https://cdn.jsdelivr.net/gh/lovevivi121/PicGo/img/%E5%BE%AE%E4%BF%A1%E5%9B%BE%E7%89%87_20240112223858.jpg"></li>
</ul>
]]></content>
      <categories>
        <category>操作系统</category>
      </categories>
      <tags>
        <tag>总结</tag>
        <tag>操作系统</tag>
      </tags>
  </entry>
  <entry>
    <title>数据库-事务隔离</title>
    <url>/posts/7/</url>
    <content><![CDATA[<h1 id="事务的基本概念"><a href="#事务的基本概念" class="headerlink" title="事务的基本概念"></a>事务的基本概念</h1><ul>
<li>事务就是保证一组数据库操作，要么全部成功，要么全部失败。在MySQL中，事务支持实在引擎层实现的，其中MyISAM引擎不支持事务。</li>
</ul>
<h1 id="隔离性与隔离级别"><a href="#隔离性与隔离级别" class="headerlink" title="隔离性与隔离级别"></a>隔离性与隔离级别</h1><h2 id="基本概念"><a href="#基本概念" class="headerlink" title="基本概念"></a>基本概念</h2><ul>
<li>事务有4大特性ACID，分别是原子性、一致性、隔离性、持久性，隔离性便是其中之一。</li>
<li>当数据库上有多个事务在同时执行时，可能出现脏读、不可重复读、幻读（TODO：解释这三个名词）的问题，为了解决这些问题，引出了“隔离级别”的概念。隔离得越严实，效率就会越低，因此需要在二者之间找到平衡。</li>
<li>SQL标准的事务隔离级别包括：读未提交、读提交、可重复读和串行化。<ul>
<li>读未提交是指其他事务能够读到一个没有提交的事务的变更。</li>
<li>读提交是指其他事务能够读到一已提交的事务的变更。</li>
<li>可重复读是指一个事务执行过程中读到的数据总是和事务启动时读到的一致。</li>
<li>串行化是指对于同一行记录，写加写锁，读加读锁，多个写操作串行访问。</li>
</ul>
</li>
</ul>
<h2 id="视图"><a href="#视图" class="headerlink" title="视图"></a>视图</h2><ul>
<li>在实现上，数据库里面会创建一个视图，访问的时候以视图的逻辑为准。在“可重复读”隔离级别下，这个视图是在事务启动的时候创建的，整个事务存在期间都用这个视图。在“读提交”隔离级别下，这个视图是在每个SQL语句开始执行时创建的。需要注意的是，对于“读未提交”隔离级别，是直接返回记录的最新值，没有视图的概念。而“串行化”隔离级别下直接用加锁的方式来避免并行访问。MySQL通过设置transaction_isolation参数修改隔离级别。</li>
</ul>
<h2 id="应用场景"><a href="#应用场景" class="headerlink" title="应用场景"></a>应用场景</h2><ul>
<li>可重复读<ul>
<li>比如希望在进行数据分析处理的过程中，不受其他事务更新的影响，就可以用“可重复读”隔离级别。</li>
</ul>
</li>
</ul>
<h2 id="事务隔离的实现"><a href="#事务隔离的实现" class="headerlink" title="事务隔离的实现"></a>事务隔离的实现</h2><ul>
<li>以可重复读为例子。在MySQL中实际上每条记录在更新时都会同时记录一条回滚操作，记录上的最新值可通过回滚得到前一个状态的值。同一条记录在系统中可以存在多个版本，就是数据库的多版本并发控制（MVCC）。不同的视图通过回滚操作得到。当系统里面没有比当前回滚日志更早的视图时，回滚日志就会删除。</li>
</ul>
<h2 id="为什么建议不要使用长事务？"><a href="#为什么建议不要使用长事务？" class="headerlink" title="为什么建议不要使用长事务？"></a>为什么建议不要使用长事务？</h2><ul>
<li>长事务意味着系统里面存在很老的事务视图。由于这些食物随时会访问数据库里面任何数据，因此在十五提交前，数据库里面它可能用到的回滚记录都必须保留，这样会导致占用大量存储空间。并且长事务占用所资源，也可能拖垮整个库。</li>
<li>你可以在 information_schema 库的 innodb_trx 这个表中查询长事务</li>
</ul>
<h2 id="事务的启动方式"><a href="#事务的启动方式" class="headerlink" title="事务的启动方式"></a>事务的启动方式</h2><ul>
<li>MySQL的启动方式有以下几种：<ul>
<li>1、显示启动事务语句，begin或者start transaction。配套的提交语句时commit，回滚语句时rollback。</li>
<li>2、set autocommit&#x3D;0，这个命令会将这个线程的自动提交关掉，意味着如果你只执行一个select语句，这个事务就启动了，而且并不会自动提交。这个事务持续存在直到你主动执行commit或者rollback语句，或者断开连接。</li>
<li>在 autocommit 为 1 的情况下，用 begin 显式启动的事务，如果执行 commit 则提交事务。如果执行 commit work and chain，则是提交事务并自动启动下一个事务，这样也省去了再次执行 begin 语句的开销。同时带来的好处是从程序开发的角度明确地知道每个语句是否处于事务中。</li>
</ul>
</li>
</ul>
]]></content>
      <categories>
        <category>MySQL</category>
      </categories>
      <tags>
        <tag>MySQL</tag>
        <tag>总结</tag>
      </tags>
  </entry>
  <entry>
    <title>数据库-普通索引和唯一索引怎么选择【索引】</title>
    <url>/posts/10/</url>
    <content><![CDATA[<h2 id="针对这个问题，就涉及到了change-buffer的相关概念"><a href="#针对这个问题，就涉及到了change-buffer的相关概念" class="headerlink" title="针对这个问题，就涉及到了change buffer的相关概念"></a>针对这个问题，就涉及到了change buffer的相关概念</h2><h3 id="change-buffer"><a href="#change-buffer" class="headerlink" title="change buffer"></a>change buffer</h3><h4 id="基本概念"><a href="#基本概念" class="headerlink" title="基本概念"></a>基本概念</h4><ul>
<li>当需要更新一个数据页的时候，如果数据页在内存中就直接更新；而如果这个数据页没有在内存中，在不影响数据一致性的前提下，InnoDB会将这些更新操作缓存在change buffer中，在下次查询需要访问这个数据页的时候，将数据页读入内存，然后执行change buffer中与这个页有关的操作。将change buffer中的操作应用到原数据页的操作叫merge，除了访问该数据页会触发merge外，有后台线程会定期merge，数据库正常关闭的时候也会merge。</li>
<li>change buffer 用的是 buffer pool 里的内存，因此不能无限增大。change buffer 的大小，可以通过参数 innodb_change_buffer_max_size 来动态设置。这个参数设置为 50 的时候，表示 change buffer 的大小最多只能占用 buffer pool 的 50%。</li>
</ul>
<h4 id="什么条件下可以使用change-buffer"><a href="#什么条件下可以使用change-buffer" class="headerlink" title="什么条件下可以使用change buffer"></a>什么条件下可以使用change buffer</h4><ul>
<li>对于唯一索引来说插入操作需要先判断是否唯一，就需要将数据页读入内存，因此唯一索引不能用change buffer，只有普通索引可以使用。</li>
<li>对于唯一索引的更新操作，假如数据页不在内存中则需要将数据读入内存，涉及到磁盘IO，而普通索引则可以将更新记录在change buffer，减少了随机磁盘访问，性能提升明显。</li>
</ul>
<h4 id="change-buffer-应用场景"><a href="#change-buffer-应用场景" class="headerlink" title="change buffer 应用场景"></a>change buffer 应用场景</h4><ul>
<li>对于写多读少的业务来说，页面写完后马上被访问到的概率较小，change buffer 被merge的频率小，收益大，典型的业务模型有账单类、日志类系统。</li>
<li>反之，如果一个业务的更新模式是写入后马上查询，那么也会由于merge而进行频繁的磁盘IO，并且还有维护change buffer的代价，吃力不讨好。</li>
</ul>
<h2 id="结论"><a href="#结论" class="headerlink" title="结论"></a>结论</h2><ul>
<li>因此针对本节的问题，对于查询操作两个索引没有区别，主要考虑更新性能的影响。尽量使用普通索引，配合change buffer提高更新性能。如果有更新完马上查询的业务就关闭change buffer。其他情况下change buffer尽量开大，提升性能。</li>
</ul>
<h2 id="redo-log和change-buffer的对比"><a href="#redo-log和change-buffer的对比" class="headerlink" title="redo log和change buffer的对比"></a>redo log和change buffer的对比</h2><ul>
<li>redo log主要节省的是随机写磁盘的IO消耗（转为顺序写），而change buffer主要节省的是随机读磁盘的IO消耗。</li>
</ul>
]]></content>
      <categories>
        <category>MySQL</category>
      </categories>
      <tags>
        <tag>MySQL</tag>
        <tag>总结</tag>
      </tags>
  </entry>
  <entry>
    <title>数据库-索引</title>
    <url>/posts/8/</url>
    <content><![CDATA[<h1 id="目的"><a href="#目的" class="headerlink" title="目的"></a>目的</h1><ul>
<li>索引的出现是为了提高数据查询的效率，就像书的目录一样。索引是一种特殊的文件，包含对数据表中所有记录的引用指针，通常使用B树及其变种B+树</li>
</ul>
<h1 id="索引的优缺点"><a href="#索引的优缺点" class="headerlink" title="索引的优缺点"></a>索引的优缺点</h1><h2 id="优点"><a href="#优点" class="headerlink" title="优点"></a>优点</h2><ul>
<li>可以加快查询速度</li>
<li>可以在查询中使用优化隐藏器，提高系统性能</li>
</ul>
<h2 id="缺点"><a href="#缺点" class="headerlink" title="缺点"></a>缺点</h2><ul>
<li>创建和维护索引需要耗费时间，降低增删改的执行效率</li>
<li>需要占用物理空间。</li>
</ul>
<h1 id="索引的常见模型"><a href="#索引的常见模型" class="headerlink" title="索引的常见模型"></a>索引的常见模型</h1><h2 id="基本概念"><a href="#基本概念" class="headerlink" title="基本概念"></a>基本概念</h2><ul>
<li>实现索引的方式有很多，可用于提高读写效率的数据结构也很多，下面从使用的角度介绍三个比较常用、简单的数据结构的区别：哈希表、有序数组和搜索树。<ul>
<li>哈希表是把key用哈希函数放到一个确定的位置，然后把value放在数组的这个位置，当多个key换算成同一个位置，则使用链表存储，查询的时候遍历链表即可。但是哈希表做区间查询速度慢，适用于只有等值查询的场景，比如Memcached以及其他一些NoSQL引擎。</li>
<li>有序数组在等值查询和范围查询中的性能都很优秀，递增的ID可通过二分法快速查询。但是在更新数据时的时间复杂度会是On，所以有序数组只适用于静态存储引擎，比如你要保存的是 2017 年某个城市的所有人口信息，这类不会再修改的数据。</li>
<li>二叉搜索树查询更新复杂度都是logn。虽然二叉树效率是最高的，但是实际上大多数数据库并不用二叉树，原因是索引不止在内存中，还要写到磁盘上。想象一下，一棵100万个节点的平衡二叉树，树高20，一次查询可能就要访问20个数据块，这样查询效率就低了。因此为了让一个查询尽量少读磁盘，就必须让查询过程访问尽量少的数据块，而磁盘查找存取的次数往往由树的高度所决定。那就应该使用“N叉树”，N取决于数据块的大小。</li>
<li>以 InnoDB 的一个整数字段索引为例，这个 N 差不多是 1200。这棵树高是 4 的时候，就可以存 1200 的 3 次方个值，这已经 17 亿了。考虑到树根的数据块总是在内存中的，一个10 亿行的表上一个整数字段的索引，查找一个值最多只需要访问 3 次磁盘。其实，树的第二层也有很大概率在内存中，那么访问磁盘的平均次数就更少了。</li>
<li>N 叉树由于在读写上的性能优点，以及适配磁盘的访问模式，已经被广泛应用在数据库引擎中了。</li>
</ul>
</li>
</ul>
<h1 id="TODO-索引的分类"><a href="#TODO-索引的分类" class="headerlink" title="TODO:索引的分类"></a>TODO:索引的分类</h1><h1 id="MySQL支持的索引类型"><a href="#MySQL支持的索引类型" class="headerlink" title="MySQL支持的索引类型"></a>MySQL支持的索引类型</h1><h1 id="B-Tree"><a href="#B-Tree" class="headerlink" title="B+Tree"></a>B+Tree</h1><h1 id="什么时候需要索引-x2F-不需要索引"><a href="#什么时候需要索引-x2F-不需要索引" class="headerlink" title="什么时候需要索引&#x2F;不需要索引"></a>什么时候需要索引&#x2F;不需要索引</h1><h1 id="InnoDB-的索引模型"><a href="#InnoDB-的索引模型" class="headerlink" title="InnoDB 的索引模型"></a>InnoDB 的索引模型</h1><h2 id="基本概念-1"><a href="#基本概念-1" class="headerlink" title="基本概念"></a>基本概念</h2><ul>
<li>在InnoDB中，表都是根据主键顺序以索引的形式存放的，这种存储方式的表称为索引组织表。又因为InnoDB使用了B+树索引模型，所以数据都是存储在B+树中的。每个索引在InnoDB里面对应一棵B+树。</li>
<li>根据叶子节点的内容，索引类型分为主键索引和非主键索引。<ul>
<li>主键索引的叶子节点存储的是整行数据。在InnoDB里，主键索引也被称为聚簇索引。</li>
<li>非主键索引的叶子节点存储的是主键的值。在InnoDB里，非主键索引也成为二级索引。</li>
</ul>
</li>
<li>基于主键索引和普通索引的查询有什么区别？<ul>
<li>假设语句是select * from T where ID &#x3D; 500 ，即主键查询方式，则只需要搜索ID这棵B+树。</li>
<li>假设语句是select * frome T where K &#x3D; 5，即普通索引查询方式，则需要先搜索K索引树，得到对应的ID，再到ID索引树搜索依次。这个过程称为回表。也就是说，基于非主键索引的查询需要多扫描一棵索引树，因此在应用中应该尽量使用主键查询。</li>
</ul>
</li>
</ul>
<h2 id="索引维护"><a href="#索引维护" class="headerlink" title="索引维护"></a>索引维护</h2><ul>
<li>基本概念<ul>
<li>B+树为了维护索引有序性，在插入新值的时候需要维护。</li>
<li>哪些场景下应该使用自增主键，而哪些场景下不应该。<ul>
<li>自增主键是指自增列上定义的主键，在建表语句中一般这么定义：NOT NULL PRIMARY KEY AUTO_INCREMENT。插入新记录的时候可以不指定ID的值，系统会获取当前ID最大值加一作为下一条记录的ID值。也就是说，每次插入一条新记录，都是追加操作，都不涉及到挪动其他记录，也不会触发B+树叶子节点的分裂。并且每个非主键索引的叶子节点都是主键的值，假如主键是其他数据类型而非整型之类，则可能会使得普通索引占用的空间更大。因此从性能和存储空间方面考量，自增主键往往是更合理的选择。</li>
<li>适合用业务字段直接做主键的场景<ul>
<li>比如场景需求如下：1、只有一个索引；2、该索引必须是唯一索引。也就是典型的KV场景。由于没有其他索引，所以也就不用考虑其他索引的叶子节点的大小问题。这时候就需要考虑到“尽量使用主键查询”的原则，直接将这个索引设置为主键，避免每次查询需要搜索两棵树。</li>
</ul>
</li>
</ul>
</li>
</ul>
</li>
</ul>
<h1 id="索引优化"><a href="#索引优化" class="headerlink" title="索引优化"></a>索引优化</h1><h2 id="如何避免回表过程？"><a href="#如何避免回表过程？" class="headerlink" title="如何避免回表过程？"></a>如何避免回表过程？</h2><ul>
<li>覆盖索引<ul>
<li>假如对于非主键索引的查询，只要查ID的值，而ID的值已经在非主键索引树上了，因此可以直接提供查询结果，避免了回表操作，对于SQL中query的所有字段，在索引B+Tree的叶子节点上都能找到的索引，称为覆盖索引。</li>
</ul>
</li>
<li>最左前缀原则<ul>
<li>基本概念<ul>
<li>最左匹配原则是说在通过联合索引检索数据时，从索引中最左边的列开始，一直向右匹配，如果遇到范围查询（&lt;&gt; between like等），就停止后边的匹配。</li>
<li>建立联合索引时，可以将选择性高的列放在索引的最前列，选择性低的放后边。在一些大字符串的字段作为索引时，使用前缀索引可以减少索引项的大小，因为不用再对大字符串字段单独建立索引了。</li>
</ul>
</li>
<li>使用到索引&#x2F;未使用的情形<ul>
<li>总结：什么情况下会索引失效？<ul>
<li>当索引列出现以下六种操作时常常出现索引失效：<ul>
<li>1、使用函数（replace\SUBSTR\CONCAT\sum count avg）、表达式、计算（+ - * &#x2F;）。因为当前值改变后就无法与索引存的值匹配上。<ul>
<li>为什么这些SQL语句逻辑相同，性能却差异巨大？（本节只是起到举一反三的作用，具体问题具体分析）（本质考点是索引失效的原因分析）<ul>
<li>条件字段函数操作<ul>
<li>eg mysql&gt; select count(*) from tradelog where month(t_modified)&#x3D;7;</li>
<li>对索引字段做函数操作，可能会破坏索引值的有序性，因此优化器放弃走树搜索功能，只能使用全索引扫描</li>
</ul>
</li>
<li>隐式类型转换<ul>
<li>egselect * from tradelog where tradeid&#x3D;110717;</li>
<li>这里面tradeid字段类型是varchar（32），而输入的参数却是整型，所以需要做类型转换。</li>
<li>MySQL中，字符串和数字作比较的话，是将字符串转换成数字，这样会将索引字段做一个函数操作，从而使得优化器放弃走树搜索功能</li>
</ul>
</li>
<li>隐式字符编码转换<ul>
<li>假如一个表是utf8，另一个是utf8-mb4，在做表连接查询的时候用不上关联字段的索引，因为也会调用convert函数将字符串转换成utf8mb4字符集。</li>
</ul>
</li>
<li>以上原因总结起来均是在索引字段上使用了函数，因此优化方法是想办法将函数加在输入参数上，这样就可以用上索引了。</li>
</ul>
</li>
</ul>
</li>
<li>2、使用范围查询(!&#x3D;,&lt;&#x3D;&gt;,in)会导致右边列失效。因为二叉树的查找是 &#x3D; 查找，若是一个范围的话无法继续下探。<ul>
<li>最左列用范围，该列也不会使用索引，全部索引列失效</li>
<li>其余列用范围，当前列仍会使用索引，但右边索引列失效</li>
<li>SELECT * FROM user_innodb where name&#x3D;’张三’ and age &gt; 22；</li>
</ul>
</li>
<li>3、like以通配符开头（‘%abc…’），mysql索引失效会变成全表扫描操作。因为无法判断%代表多少字符。<ul>
<li>方案一：like (‘abc%’)</li>
<li>方案二：覆盖索引<ul>
<li>SELECT * FROM user_innodb where name like ‘%三’；</li>
</ul>
</li>
</ul>
</li>
<li>4、字符串不加’ ‘索引失效。因为会出现出现隐式转换，相当于给索引列做了操作。<ul>
<li>SELECT * FROM user_innodb where name &#x3D; 007；– “007”从字符串变成了数字007</li>
</ul>
</li>
<li>5、少用or，用它连接时很多情况下索引会失效<ul>
<li>SELECT * FROM user_innodb where name &#x3D; ‘张三’ or name &#x3D; ‘李四’；</li>
</ul>
</li>
<li>6、is null，is not null 无法使用索引<ul>
<li>SELECT * FROM user_innodb where name is null；</li>
</ul>
</li>
<li>总结打油诗<ul>
<li>全值匹配我最爱，最左前缀要遵守<ul>
<li>带头大哥不能死，中间兄弟不能断</li>
<li>索引列上少计算，范围之后全失效</li>
<li>like百分写最右，覆盖索引不写星</li>
<li>不等空值还有or，索引失效要少用</li>
</ul>
</li>
</ul>
</li>
</ul>
</li>
<li>可以乱序<ul>
<li>比如a &#x3D; 1 and b &#x3D; 2 and c &#x3D; 3 建立(a,b,c)索引可以任意顺序。</li>
</ul>
</li>
</ul>
</li>
</ul>
</li>
<li>索引下推<ul>
<li>基本概念<ul>
<li>索引下推ICP是MySQL5.6版本的新特性，它能够减少回表查询次数，提高查询效率</li>
</ul>
</li>
<li>实现原理<ul>
<li>在没有ICP的情况下，查询过程如下：<ul>
<li>存储引擎读取索引记录，回表，将全部记录交给服务层检测是否满足where条件</li>
</ul>
</li>
<li>使用ICP后的查询过程：<ul>
<li>存储引擎读取索引记录，判断条件部分能否使用索引中的列做检查，条件不满足，则处理下一行索引记录；条件满足则回表，然后交给服务层检测其余条件。显然这样会减少回表次数。</li>
</ul>
</li>
</ul>
</li>
</ul>
</li>
</ul>
</li>
<li>插入优化<ul>
<li>索引最好是自增的，如果不自增，因B+树要求需要按主键顺序排列，再插入新数据的时候会产生大量的数据移动。</li>
</ul>
</li>
</ul>
]]></content>
      <categories>
        <category>MySQL</category>
      </categories>
      <tags>
        <tag>MySQL</tag>
        <tag>总结</tag>
      </tags>
  </entry>
  <entry>
    <title>计网-传输层八股（一）</title>
    <url>/posts/11/</url>
    <content><![CDATA[<h1 id="3-10-简述-TCP-和-UDP-的区别，它们的头部结构是什么样的"><a href="#3-10-简述-TCP-和-UDP-的区别，它们的头部结构是什么样的" class="headerlink" title="3.10 简述 TCP 和 UDP 的区别，它们的头部结构是什么样的"></a>3.10 简述 TCP 和 UDP 的区别，它们的头部结构是什么样的</h1><ul>
<li>1、有连接，无连接</li>
<li>2、按序到达，提供超时重传；U不保证按序到达，甚至不保证到达</li>
<li>3、T首部20B以上，U只需8B</li>
<li>4、TCP有流量控制和拥塞控制；U无，网络堵塞不影响发送的速率</li>
<li>5、T是一对一的；U反过来</li>
<li>6、T面向字节流，数据没有边界，会出现粘包拆包问题；U面向报文段，有消息边界</li>
<li>7、可靠，不可靠</li>
<li>8、速度快慢</li>
<li>9、应用场景，t适合对连接可靠性要求比较高，传输量大的场景，比如；u适合实时性高的场景，比如视频通话，游戏等</li>
</ul>
<h3 id="头部结构"><a href="#头部结构" class="headerlink" title="头部结构"></a>头部结构</h3><ul>
<li>源目序确首保标窗校紧</li>
<li>udp：源目长校</li>
</ul>
<h1 id="3-8-简述-TCP-三次握手和四次挥手的过程"><a href="#3-8-简述-TCP-三次握手和四次挥手的过程" class="headerlink" title="3.8 简述 TCP 三次握手和四次挥手的过程"></a>3.8 简述 TCP 三次握手和四次挥手的过程</h1><ul>
<li>sasa</li>
<li>fafa</li>
</ul>
<h1 id="3-9-说说-TCP-2次握手行不行？为什么要3次"><a href="#3-9-说说-TCP-2次握手行不行？为什么要3次" class="headerlink" title="3.9 说说 TCP 2次握手行不行？为什么要3次"></a>3.9 说说 TCP 2次握手行不行？为什么要3次</h1><ul>
<li>tcp连接双方都维护了一个序列号，标识哪些是已经接收的包，三次握手是告知并确认序列起始值的毕竟步骤</li>
<li>若两次，最多只有c的序列号能被s确认，s不能确认c的</li>
</ul>
<h1 id="3-12-简述-TCP-连接-和-关闭的状态转移"><a href="#3-12-简述-TCP-连接-和-关闭的状态转移" class="headerlink" title="3.12 简述 TCP 连接 和 关闭的状态转移"></a>3.12 简述 TCP 连接 和 关闭的状态转移</h1><ul>
<li>closed-listen（s端监听端口）-syn_sent（第一次）-syn_rcvd（第二次）-established</li>
</ul>
<h1 id="3-20-说说如果三次握手时候每次握手信息对方没收到会怎么样，分情况介绍"><a href="#3-20-说说如果三次握手时候每次握手信息对方没收到会怎么样，分情况介绍" class="headerlink" title="3.20 说说如果三次握手时候每次握手信息对方没收到会怎么样，分情况介绍"></a>3.20 说说如果三次握手时候每次握手信息对方没收到会怎么样，分情况介绍</h1><ul>
<li>第一二次握手消息丢失，收不到ack，会进行重传；</li>
<li>第三次握手消息丢失，server端会重新发syn+ack包，</li>
<li>而Server重发SYN+ACK包的次数，可以设置&#x2F;proc&#x2F;sys&#x2F;net&#x2F;ipv4&#x2F;tcp_synack_retries修改，默认值为5.</li>
<li>RTO超时重传时间是成倍增长的</li>
</ul>
<h1 id="3-21-简述-TCP-的-TIME-WAIT，为什么需要有这个状态，说说MSL"><a href="#3-21-简述-TCP-的-TIME-WAIT，为什么需要有这个状态，说说MSL" class="headerlink" title="3.21 简述 TCP 的 TIME_WAIT，为什么需要有这个状态，说说MSL"></a>3.21 简述 TCP 的 TIME_WAIT，为什么需要有这个状态，说说MSL</h1><ul>
<li>time_wait也成为2MSL等待状态，MSL是报文段最大生存时间；</li>
<li>主动关闭时，连接必须在time_wait状态停留2MSL时间，有两个原因，一个是保证最后的ACK到达S端，如果该ack丢失，则S端会重发FIN包，无法正常进入关闭连接状态；另一方面是防止新的相同IP和端口的连接出现旧连接的报文段，2MSL可以保证旧连接的报文段都被消失</li>
</ul>
<h1 id="3-23-说说什么是-SYN-flood，如何防止这类攻击？"><a href="#3-23-说说什么是-SYN-flood，如何防止这类攻击？" class="headerlink" title="3.23 说说什么是 SYN flood，如何防止这类攻击？"></a>3.23 说说什么是 SYN flood，如何防止这类攻击？</h1><ul>
<li>发大量伪造TCP请求，使得被攻击方资源耗尽</li>
</ul>
<h3 id="防止："><a href="#防止：" class="headerlink" title="防止："></a>防止：</h3><ul>
<li>CDN</li>
</ul>
<h1 id="3-24-说说什么是-TCP-粘包和拆包？"><a href="#3-24-说说什么是-TCP-粘包和拆包？" class="headerlink" title="3.24 说说什么是 TCP 粘包和拆包？"></a>3.24 说说什么是 TCP 粘包和拆包？</h1><ul>
<li>tcp是面向数据流的，数据没有分界线，tcp会根据缓冲区的实际情况进行划分，可能把数据分成多个小包，也可能将两个数据包封装成一个大的数据包发送，有四种情形；</li>
</ul>
<h3 id="解决措施："><a href="#解决措施：" class="headerlink" title="解决措施："></a>解决措施：</h3><ul>
<li>约定好分隔符</li>
<li>预定好包长度</li>
<li>消息头+消息体</li>
</ul>
<h1 id="3-14-说说-TCP-如何保证有序"><a href="#3-14-说说-TCP-如何保证有序" class="headerlink" title="3.14 说说 TCP 如何保证有序"></a>3.14 说说 TCP 如何保证有序</h1><ul>
<li>发送方角度，每发送一个包就对应一个序列号，并在特定时间等待接收方确认，若没收到应答则重传</li>
<li>接收方角度，会将数据按正确顺序重组成数据流交给上层，然后发送应答包。</li>
</ul>
<h1 id="3-16-简述-TCP-超时重传"><a href="#3-16-简述-TCP-超时重传" class="headerlink" title="3.16 简述 TCP 超时重传"></a>3.16 简述 TCP 超时重传</h1><ul>
<li>是保证可靠传输最重要的机制；每发送一个报文段，就会启动一个计数器并等待确认；接收方接收后发送确认报文；若未在规定时间被确认，则重传</li>
</ul>
]]></content>
      <categories>
        <category>计算机网络</category>
      </categories>
      <tags>
        <tag>blog</tag>
        <tag>计算机网络</tag>
      </tags>
  </entry>
  <entry>
    <title>数据库-日志系统</title>
    <url>/posts/5/</url>
    <content><![CDATA[<h1 id="更新语句的执行流程？"><a href="#更新语句的执行流程？" class="headerlink" title="更新语句的执行流程？"></a>更新语句的执行流程？</h1><ul>
<li>和查询流程不同的是，更新语句还要涉及两个重要的日志模块，分别是redo log（重做日志）和binlog（归档日志）。</li>
</ul>
<h1 id="redo-log"><a href="#redo-log" class="headerlink" title="redo log"></a>redo log</h1><ul>
<li>问题提出<ul>
<li>加入对于MySQL的每次更新操作都要写进磁盘，然后磁盘也得找到对应的那条记录，然后才能更新，整个过程的IO、查询成本太高。</li>
</ul>
</li>
<li>解决方案（WAL）<ul>
<li>基本概念（写日志，更新，跟新，固定，循环，crashsafe）<ul>
<li>为了解决这个问题，MySQL使用到了WAL技术，全称Write-Ahead Logging。它的关键点是先写日志，再写磁盘。具体来说，当有一条记录需要更新时，InnoDB引擎会先把记录写到redo log里面，并且更新内存，这时候更新操作就算完成了。同时InnoDB会再实弹的时候将这个操作记录更新到磁盘里面。InnoDB的redo log是固定大小的，比如可以配置为一组4个文件，一个文件1GB，总共4GB，写入时，从头开始，写到末尾就回到开头，循环写。有了redo log，InnoDB就可以保证即使数据库发生异常重启，之前提交的记录也不会丢失，该能力称为crash-safe。redo log是InnoDB引擎特有的日志。</li>
</ul>
</li>
<li>redo log实现机制（write 位置，后移，循环，check 擦除，空着，追上）<ul>
<li>在实现中，有两个主要字段分别是write pos和check point。write pos记录当前位置，一边写一边后移，写到第3号文件末尾后就回到0号文件开头。check point是当前要擦除的位置，也是往后推移并且循环的，擦除记录前要把记录更新到数据文件。writepos和checkpoint之间空着的部分，便是可以用来记录新的操作。如果write pos追上了check point，表示已经满了，此时不能再执行更新操作，需要先擦掉一些记录，把check point前推一些。</li>
</ul>
</li>
</ul>
</li>
</ul>
<h1 id="binlog"><a href="#binlog" class="headerlink" title="binlog"></a>binlog</h1><ul>
<li><p>基本概念（server层，归档）</p>
<ul>
<li>binlog是MySQL的Server层的二进制日志，用于记录所有对数据库的增删改操作，叫做归档日志。</li>
</ul>
</li>
<li><p>为什么有两个日志？（MyISQM无crashsafe能力，binlog只能用于归档，InnoDB引擎便使用另外日志系统redo来实现）</p>
<ul>
<li>因为最开始 MySQL 里并没有 InnoDB 引擎。MySQL 自带的引擎是 MyISAM，但是MyISAM 没有 crash-safe 的能力，binlog 日志只能用于归档。而 InnoDB 是另一个公司以插件形式引入 MySQL 的，既然只依靠 binlog 是没有 crash-safe 能力的，所以 InnoDB使用另外一套日志系统——也就是 redo log 来实现 crash-safe 能力。</li>
</ul>
</li>
<li><p>redo log 和 binlog有什么不同？</p>
<ol>
<li>redo log 是 InnoDB 引擎特有的；binlog 是 MySQL 的 Server 层实现的，所有引擎都可以使用。</li>
<li>redo log 是物理日志，记录的是“在某个数据页上做了什么修改”；binlog 是逻辑日志，记录的是这个语句的原始逻辑，比如“给 ID&#x3D;2 这一行的 c 字段加 1 ”。</li>
<li>redo log 是循环写的，空间固定会用完；binlog 是可以追加写入的。“追加写”是指binlog 文件写到一定大小后会切换到下一个，并不会覆盖以前的日志。</li>
</ol>
</li>
<li><p>执行器和InnoDB引擎在语句update T set c&#x3D;c+1 where ID&#x3D;2;中的内部流程</p>
<ol>
<li>执行器首先找到引擎取ID&#x3D;2这一行，ID是主键，引擎直接用树搜索找到这一行。如果ID&#x3D;2这一行所在的数据页本来就在内存中，就直接返回给执行器；否则选哟先从磁盘中读入内存，然后再返回。</li>
<li>执行器拿到引擎给的行数据后，把这个值加上1，得到新的一行数据，再调用引擎接口写入新数据。</li>
<li>引擎将这一行新数据更新到内存中，同时将这个更新操作记录到redo log里面，此时redo log处于prepare状态。然后告知执行器完成了，随时可以提交事务。</li>
<li>执行器生成这个操作的binlog，并把binlog写入磁盘。</li>
<li>执行器调用引擎的提交事务接口，引擎把刚写入的redo log改成提交（commit）状态，更新完成</li>
</ol>
</li>
<li><p>为什么必须有两阶段提交？</p>
<ul>
<li>什么是<ul>
<li>两阶段提交是说redo log 先 prepare，再刷新 binlog ，再 redo log commit 的过程。</li>
</ul>
</li>
<li>原因<ul>
<li>要说明这个问题，首先追溯到另一个问题：怎样让数据库恢复到半个月内任意一秒的状态？首先通过找到最近一次全量备份，并记录下备份时间点。接着从这个时间点开始将备份的binlog依次取出，重放到需要的时间点。这样临时库就和误删之前的线上库一样了，然后可以把表中的数据从临时库中取出来，按需要恢复到线上去。</li>
<li>说完恢复过程，再回来说说为什么需要两阶段提交。这里用反证法进行解释。假设不用两阶段提交，那么要么就是先写完redo log再写完binlog，要么就是先写完binlog再写完redo log。假设先写binlog后写redo log，在写完binlog后写完redo log前，MySQL宕机了，会导致线上库并没有更新，但是binlog里面已经记录了更新日志，所以临时库和线上库会出现大量的不一致的数据。假设先写完redo log并且在写完binlog之前，MySQL宕机了，此时线上库已经更新了数据，而binlog没有这条更新日志，所以临时库会缺失大量更新导致和线上库数据不一致，而且redo log在做恢复的时候每次都需要去binlog查看该事务是否已经写入，严重影响了性能。而如果是两阶段提交，处于 commit 阶段的事务都会直接恢复，处于 prepare 阶段才需要去看 binlog。</li>
<li>假如使用两段式提交，在MySQL宕机恢复的时候，如果发现redo log 中某个事务处于commit状态，则说明binlog一定记录了，直接恢复即可；如果redo log 某个事务处于prepare状态，则查看binlgo中是否有该事务的数据（依据全局唯一事务ID），如果有，则恢复，否则丢弃redo log的该条事务。这样从而保证redo log 和binlog 的数据一致性。</li>
</ul>
</li>
</ul>
</li>
</ul>
]]></content>
      <categories>
        <category>MySQL</category>
      </categories>
      <tags>
        <tag>MySQL</tag>
        <tag>总结</tag>
      </tags>
  </entry>
  <entry>
    <title>数据库：说一说InnoDB刷脏页</title>
    <url>/posts/6/</url>
    <content><![CDATA[<h1 id="为什么SQL语句正常时很快，有时很慢？也就是“抖”一下（本质就是问说一说InnoDB刷脏页）"><a href="#为什么SQL语句正常时很快，有时很慢？也就是“抖”一下（本质就是问说一说InnoDB刷脏页）" class="headerlink" title="为什么SQL语句正常时很快，有时很慢？也就是“抖”一下（本质就是问说一说InnoDB刷脏页）"></a>为什么SQL语句正常时很快，有时很慢？也就是“抖”一下（本质就是问说一说InnoDB刷脏页）</h1><h1 id="原因分析"><a href="#原因分析" class="headerlink" title="原因分析"></a>原因分析</h1><ul>
<li>可能是在刷脏页（flush）（脏页即当内存数据页跟磁盘数据页内容不一致的时候，称这个内存页为脏页。）<ul>
<li>第一种情况是redo log写满了。这时候系统会停止所有更新操作，把checkpoint往前推进，并且刷脏页，redo log留出空间可以继续写。</li>
<li>第二种情况就是系统内存不足。这时候会要淘汰一些数据页，如果淘汰的是“脏页”，需要先将脏页写入磁盘。<ul>
<li>InnoDB缓冲池中的内存页的三种状态<ul>
<li>还没使用的</li>
<li>使用了的干净页</li>
<li>使用了的脏页</li>
</ul>
</li>
<li>申请数据页<ul>
<li>当要读入的数据页没有在内存的时候，就必须到缓冲池中申请一个数据页。这时候得把最久不使用的数据页从内存中淘汰掉。当淘汰的是脏页的时候就得先刷脏页，出现以下两种情况便会影响性能<ul>
<li>一个查询要淘汰的脏页个数太多，导致这个查询的响应时间明显变长。</li>
<li>日志写满了，更新全堵住，写性能跌为0。</li>
</ul>
</li>
</ul>
</li>
</ul>
</li>
<li>第三种情况是MySQL认为系统处于“空闲”状态，会进行刷脏页，但既然都是空闲了，不太可能影响性能</li>
<li>第四种情况是MySQL正常关闭的情况，也会刷脏页。正常关闭了，也不会影响性能。</li>
</ul>
<h1 id="InnoDB刷脏页的控制策略"><a href="#InnoDB刷脏页的控制策略" class="headerlink" title="InnoDB刷脏页的控制策略"></a>InnoDB刷脏页的控制策略</h1><ul>
<li>为什么需要<ul>
<li>InnoDB需要有控制脏页比例的机制，来尽量避免一次性淘汰的脏页过多或者日志写满影响读写性能。</li>
<li>刷脏页具体机制以及这些策略相关的参数<ul>
<li>首先通过设置innodb_io_capacity告诉InnoDB磁盘读写能力，通常设置成磁盘的IOPS，可通过fio工具测试，得到InnoDB最大刷脏页速度。</li>
<li>InnoDB通过全力的百分比来刷脏页<ul>
<li>InnoDB会先根据脏页占整个缓存池的比例以及redo log写盘速度两个因素算出两个值。<ul>
<li>参数innodb_maxdirty_pages_pct是脏页的比例上限，默认75%。</li>
<li>第一个值是依据脏页占缓存池的比例算出来的</li>
<li>第二个值是根据redo log中write pos和checkpoint的差值计算出来的</li>
<li>最后按照最大刷脏页速度 * max（f1，f2）%的速度刷脏页</li>
</ul>
</li>
</ul>
</li>
</ul>
</li>
</ul>
</li>
</ul>
</li>
</ul>
]]></content>
      <categories>
        <category>MySQL</category>
      </categories>
      <tags>
        <tag>MySQL</tag>
        <tag>总结</tag>
      </tags>
  </entry>
  <entry>
    <title>数据库-基本架构</title>
    <url>/posts/4/</url>
    <content><![CDATA[<h1 id="大体上MySQL可以分为Server层和引擎层两个部分"><a href="#大体上MySQL可以分为Server层和引擎层两个部分" class="headerlink" title="大体上MySQL可以分为Server层和引擎层两个部分"></a>大体上MySQL可以分为Server层和引擎层两个部分</h1><h1 id="Server层"><a href="#Server层" class="headerlink" title="Server层"></a>Server层</h1><ul>
<li><p>Server层包括连接器、查询缓存、分析器、优化器、执行器，涵盖MySQL的大多数核心服务功能，以及所有的内置函数（如日期、时间、数学和加密函数等），所有跨存储引擎的功能都在这一层实现，比如存储过程、触发器、视图等。</p>
<h1 id="连接器"><a href="#连接器" class="headerlink" title="连接器"></a>连接器</h1><ul>
<li>基本概念<ul>
<li>当客户端连接到数据库上的时候，首先接待的便是连接器，连接器负责跟客户端建立连接，获取权限，维持和管理连接。</li>
</ul>
</li>
<li>连接流程<ul>
<li>连接的命令如下<code>-h$ip -p$port -u$user -p</code> 接着输入密码。完成TCP握手后连接器就会开始身份认证。如果用户或者密码不对就会报<code>Access denied for user</code>错误，客户端结束运行。如果认证通过，接下来连接器会到权限表里面获取当前用户的所有权限。之后该连接的所有权限判断都依据当前获取的权限，意味着即使权限被修改了，也需要重新连接才能使用新的权限。</li>
<li>完成连接后，如果没有操作该连接便会进入空闲状态，可在show processlist里面查看连接的状态。如果连接超过wait_timeout时间没有动作，默认是8小时，则会将连接断开，如果此时再发起请求将会报<code>Lost connection to MySQL server during query</code>错误。</li>
</ul>
</li>
<li>长连接与短链接<ul>
<li>基本概念<ul>
<li>长连接是指如果客户端一直有请求则一直使用该连接。短连接是指每次执行过很少请求后就断开连接，下次查询再重新连接。由于连接过程复杂，所以推荐使用长连接。</li>
</ul>
</li>
<li>长连接的问题与解决方案<ul>
<li>问题提出<ul>
<li>MySQL执行过程中使用的内存是在连接内部的，这些资源会在连接断开的时候才释放。如果使用长连接，积累过多了会导致内存暴涨，这个时候系统会强行kill连接，表现出来就是MySQL异常重启了。</li>
</ul>
</li>
<li>解决方案<ul>
<li>一个是定期断开长连接，或者执行了一个占用内存大的查询后，断开连接并重连。</li>
<li>另一个是5.7版本后可以使用<code>mysql_reset_connection</code>重新初始化连接资源,不用断开连接。</li>
</ul>
</li>
</ul>
</li>
</ul>
</li>
</ul>
<h1 id="查询缓存"><a href="#查询缓存" class="headerlink" title="查询缓存"></a>查询缓存</h1><ul>
<li>基本概念<ul>
<li>建立连接后执行逻辑会来到查询缓存。MySQL 拿到一个查询请求后，会先到查询缓存看看，之前是不是执行过这条语句。之前执行过的语句及其结果可能会以 key-value 对的形式，被直接缓存在内存中。key 是查询的语句，value 是查询的结果。如果你的查询能够直接在这个缓存中找到 key，那么这个value 就会被直接返回给客户端。如果语句不在查询缓存中，就会继续后面的执行阶段。执行完成后，执行结果会被存入查询缓存中。但是查询缓存的失效非常频繁，只要有对一个表的更新，这个表上所有的查询缓存都会被清空。对于更新压力大的数据库来说，查询缓存的命中率会非常低。除非你的业务就是有一张静态表，很长时间才会更新一次。比如，一个系统配置表，那这张表上的查询才适合使用查询缓存。</li>
</ul>
</li>
<li>按需使用<ul>
<li>MySQL 提供了“按需使用”的方式。你可以将参数 query_cache_type 设置成 DEMAND，这样对于默认的 SQL 语句都不使用查询缓存。而对于你确定要使用查询缓存的语句，可以用 SQL_CACHE 显式指定，像下面这个语句一样：mysql&gt; select SQL_CACHE * from T where ID&#x3D;10；</li>
<li>MySQL 8.0 版本直接将查询缓存的整块功能删掉了。</li>
</ul>
</li>
</ul>
<h1 id="分析器"><a href="#分析器" class="headerlink" title="分析器"></a>分析器</h1><ul>
<li>基本概念<ul>
<li>如果没有命中查询缓存，则接下来要开始真正执行语句了。首先MySQL需要知道你要做什么，因此需要对SQL语句做解析。</li>
</ul>
</li>
<li>语句解析分为了词法分析和语法分析<ul>
<li>词法分析<ul>
<li>分析的是SQL语句的字符串中分别是什么，代表什么。比如select就标识为查询语句，ID识别为列ID等</li>
</ul>
</li>
<li>语法分析<ul>
<li>是用来判断SQL语句是否满足MySQL语法，如果不满足则报You have an error in your SQL syntax错误</li>
</ul>
</li>
</ul>
</li>
</ul>
<h1 id="优化器"><a href="#优化器" class="headerlink" title="优化器"></a>优化器</h1><ul>
<li>在开始执行前，还要经过优化器处理。优化器是在表里面有多个索引的时候，决定使用哪个索引，或者在一个语句有多个表关联（join）时，决定各表的连接顺序，这些都会导致执行效率的不同。</li>
</ul>
<h1 id="执行器"><a href="#执行器" class="headerlink" title="执行器"></a>执行器</h1><ul>
<li>接下来就是进入执行器阶段，开始执行语句。</li>
<li>基本流程<ul>
<li>开始执行的时候，要先判断一下你对这个表 T 有没有执行查询的权限，如果没有，就会返回没有权限的错误。如果有权限，就打开表继续执行。打开表的时候，执行器就会根据表的引擎定义，去使用这个引擎提供的接口。</li>
<li>比如我们要查询表 T 中ID为10的数据，并且ID 字段没有索引，那么执行器的执行流程是这样的：1. 调用 InnoDB 引擎接口取这个表的第一行，判断 ID 值是不是 10，如果不是则跳过，如果是则将这行存在结果集中；2. 调用引擎接口取“下一行”，重复相同的判断逻辑，直到取到这个表的最后一行。3. 执行器将上述遍历过程中所有满足条件的行组成的记录集作为结果集返回给客户端。</li>
<li>对于有索引的表，执行的逻辑也差不多。第一次调用的是“取满足条件的第一行”这个接口，之后循环取“满足条件的下一行”这个接口，这些接口都是引擎中已经定义好的。</li>
<li>在数据库的慢查询日志中看到一个 rows_examined 的字段，表示这个语句执行过程中扫描了多少行。这个值就是在执行器每次调用引擎获取数据行的时候累加的。</li>
</ul>
</li>
</ul>
</li>
</ul>
<h1 id="存储引擎"><a href="#存储引擎" class="headerlink" title="存储引擎"></a>存储引擎</h1><ul>
<li>什么是存储引擎？<ul>
<li>存储引擎层负责数据的存储和提取，直接与磁盘交互部分。页是存储引擎读写数据的最小单位，一个页里可以有一条或多条表记录。其架构模式是插件式的，支持 InnoDB、MyISAM、Memory 等多个存储引擎。现在最常用的存储引擎是 InnoDB，它从 MySQL 5.5.5 版本开始成为了默认存储引擎，而 InnoDB 是 MySQL 中唯一能够完整支持事务特性的存储引擎。你执行 create table 建表的时候，如果不指定引擎类型，默认使用的就是InnoDB。不过，你也可以通过指定存储引擎的类型来选择别的引擎，比如在 create table语句中使用 engine&#x3D;memory, 来指定使用内存引擎创建表。</li>
</ul>
</li>
<li>什么是随机 IO 和顺序 IO？<ul>
<li>磁盘读写数据的两种方式。随机 IO 需要先找到地址，再读写数据，每次拿到的地址都是随机的。而顺序 IO，由于地址是连贯的，找到地址后，一次可以读写许多数据，效率比较高。</li>
</ul>
</li>
</ul>
]]></content>
      <categories>
        <category>MySQL</category>
      </categories>
      <tags>
        <tag>MySQL</tag>
        <tag>总结</tag>
      </tags>
  </entry>
</search>
